import time
import queue
import sounddevice as sd
import numpy as np
import nls
import sys
import threading
import json
from ppt_controller import get_ppt_controller
import re

# é˜¿é‡Œäº‘é…ç½®ä¿¡æ¯
URL = "wss://nls-gateway-cn-shanghai.aliyuncs.com/ws/v1"
TOKEN = "d47f354604834d0e846aeff5d332a951"  # å®é™…Tokenï¼Œè¿™æ˜¯ä¸´æ—¶çš„å…è´¹çš„ï¼Œå¯èƒ½éœ€è¦æ¯24å°æ—¶æ¢ä¸€ä¸ª
APPKEY = "Th4Q3N8Q2BRXGhNg"  # å®é™…Appkey

# è®°å½•éŸ³é¢‘æ•°æ®çš„é˜Ÿåˆ—
audio_queue = queue.Queue()

# æ§åˆ¶è¯­éŸ³è¯†åˆ«çš„å¼€å¯å’Œå…³é—­
RUNNING: bool = False
running_lock = threading.Lock()  # ç”¨äºä¿æŠ¤RUNNINGå˜é‡çš„é”
page_lock = threading.Lock()  # ç¿»é¡µé”

output_lock = threading.Lock()


# ä»éº¦å…‹é£è¾“å…¥éŸ³é¢‘çš„å›è°ƒå‡½æ•° å‘éŸ³é¢‘é˜Ÿåˆ—ä¸­æ·»åŠ æ•°æ®
def audio_callback(indata, frames, time, status):
    if status:
        #print(f"ğŸ¤ DEBUG: éŸ³é¢‘çŠ¶æ€è­¦å‘Š: {status}", file=sys.stderr)
        x=1
    # æ·»åŠ ç®€å•çš„éŸ³é¢‘æ´»åŠ¨æ£€æµ‹
    volume = np.sqrt(np.mean(indata**2))
    if volume > 0.01:  # å¦‚æœæœ‰è¶³å¤Ÿçš„éŸ³é¢‘ä¿¡å·
        #print(f"ğŸ¤ DEBUG: æ£€æµ‹åˆ°éŸ³é¢‘ä¿¡å·ï¼ŒéŸ³é‡: {volume:.4f}")
        x=1
    audio_queue.put(indata.copy())


class RealTimeSpeechRecognizer:
    def __init__(self, url=URL, token=TOKEN, appkey=APPKEY):
        self.url = url
        self.token = token
        self.appkey = appkey
        self.transcriber = None
        self.current_text = ""  # å­˜å‚¨å½“å‰è¯†åˆ«çš„æ–‡æœ¬
        self.last_complete_sentence = ""  # å­˜å‚¨æœ€åå®Œæˆçš„å¥å­
        self.__initialize_transcriber()

        # æ¢é¡µå…³é”®è¯
        self.next_page_keywords = []
        self.prev_page_keyword = "ä¸Šä¸€é¡µ"
    def __initialize_transcriber(self):
        print(f"ğŸ”§ DEBUG: åˆå§‹åŒ–é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«å™¨...")
        print(f"ğŸ”§ URL: {self.url}")
        print(f"ğŸ”§ APPKEY: {self.appkey}")
        print(f"ğŸ”§ TOKEN: {self.token[:20]}...") # åªæ˜¾ç¤ºå‰20ä¸ªå­—ç¬¦
        
        try:
            self.transcriber = nls.NlsSpeechTranscriber(
                url=self.url,
                token=self.token,
                appkey=self.appkey,
                on_sentence_begin=self.on_sentence_begin,
                on_sentence_end=self.on_sentence_end,
                on_start=self.on_start,
                on_result_changed=self.on_result_changed,
                on_completed=self.on_completed,
                on_error=self.on_error,
                on_close=self.on_close
            )
            print("âœ… NlsSpeechTranscriber åˆ›å»ºæˆåŠŸ")
            
            self.transcriber.start(aformat="pcm",
                                   enable_intermediate_result=True,
                                   enable_punctuation_prediction=True,
                                   enable_inverse_text_normalization=True)
            print("âœ… é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«å™¨å¯åŠ¨æˆåŠŸ")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«å™¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    def send_audio(self, audio_data):
        if self.transcriber:
            self.transcriber.send_audio(audio_data)

    def stop_transcription(self):
        if self.transcriber:
            self.transcriber.stop()

    def get_current_text(self):
        """è·å–å½“å‰è¯†åˆ«çš„æ–‡æœ¬"""
        return self.current_text

    def get_last_complete_sentence(self):
        """è·å–æœ€åå®Œæˆçš„å¥å­"""
        return self.last_complete_sentence

    def on_sentence_begin(self, message, *args):
        # è§£æJSONæ¶ˆæ¯
        try:
            data = json.loads(message)
            result = data.get('payload', {}).get('result', '')
            self.current_text = result
            # with output_lock:
            #     print(f"\n[å¼€å§‹] {result}")
        except json.JSONDecodeError:
            # print(f"è§£æé”™è¯¯: {message}")
            pass

    def detect_page_jump_command(self, text):
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹è·³è½¬é¡µé¢æŒ‡ä»¤
        æ”¯æŒä¸­è‹±æ–‡æ··åˆè¡¨è¾¾ï¼Œå¦‚ï¼š
          "è·³è½¬åˆ°ç¬¬5é¡µ"
          "go to page 10"
          "ç¿»åˆ°ç¬¬3é¡µ"
          "jump to page 15"
        """
        # ç»Ÿä¸€è½¬æ¢ä¸ºå°å†™ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        normalized_text = text.lower()
        # å®šä¹‰è·³è½¬é¡µé¢çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        # ä¸­æ–‡æ¨¡å¼ï¼šåŒ¹é… "è·³è½¬[åˆ°/è‡³]ç¬¬Xé¡µ" æˆ– "ç¿»åˆ°ç¬¬Xé¡µ"
        chinese_pattern = r'(?:è·³è½¬|ç¿»|è½¬åˆ°|åˆ‡æ¢)[åˆ°è‡³]?ç¬¬?(\d+)[é¡µå¼ ]'
        # è‹±æ–‡æ¨¡å¼ï¼šåŒ¹é… "go to page X" æˆ– "jump to page X"
        english_pattern = r'(?:go|jump|switch)\s*to\s*page\s*(\d+)'
        # ç»„åˆä¸­è‹±æ–‡æ¨¡å¼
        combined_pattern = f"({chinese_pattern})|({english_pattern})"
        # åœ¨æ–‡æœ¬ä¸­æœç´¢åŒ¹é…
        match = re.search(combined_pattern, normalized_text)
        if match:
            # æå–é¡µç æ•°å­—ï¼ˆä¼˜å…ˆå–ä¸­æ–‡åŒ¹é…ï¼Œå¦‚æœæ²¡æœ‰åˆ™å–è‹±æ–‡åŒ¹é…ï¼‰
            page_num = match.group(1) or match.group(3)
            if page_num:
                try:
                    page_num = int(page_num)
                    # æ‰§è¡Œè·³è½¬æ“ä½œ
                    get_ppt_controller().jump_to_slide(page_num)
                except ValueError:
                    # print(f"æå–çš„é¡µç æ— æ•ˆ: {page_num}")
                    pass

    def on_sentence_end(self, message, *args):
        # è§£æJSONæ¶ˆæ¯
        try:
            data = json.loads(message)
            result = data.get('payload', {}).get('result', '')
            self.current_text = ""
            self.last_complete_sentence = result  # ä¸€å¥å®Œæ•´çš„ä¸ä¸­æ–­çš„è¯
            # å½“ä¸€æ®µè¿ç»­ä¸ä¸­æ–­çš„è¯ç»“æŸ é˜¿é‡Œäº‘çš„sdkä¼šè‡ªåŠ¨è°ƒç”¨è¯¥å‡½æ•° åœ¨è¿™é‡Œè°ƒç”¨PPTæ¢é¡µçš„é€»è¾‘
            with page_lock:
                next_page_keyword = [kw for kw in self.next_page_keywords if kw in result]
                if next_page_keyword:
                    get_ppt_controller().next_slide()
                elif self.prev_page_keyword in result:
                    get_ppt_controller().previous_slide()
                # else:
                #     self.detect_page_jump_command(result)
            with output_lock:
                print(f"\n[å®Œæ•´å¥å­] {result}")
        except json.JSONDecodeError:
            # print(f"è§£æé”™è¯¯: {message}")
            pass   
        
    def on_start(self, message, *args):
        print(f"ğŸ”§ DEBUG: on_start è¢«è°ƒç”¨: {message}")

    def on_result_changed(self, message, *args):
        # è§£æJSONæ¶ˆæ¯ - è¿™æ˜¯å®æ—¶æ›´æ–°çš„æ–‡æœ¬
        print(f"ğŸ”§ DEBUG: on_result_changed è¢«è°ƒç”¨: {message}")
        try:
            data = json.loads(message)
            result = data.get('payload', {}).get('result', '')
            self.current_text = result
            if result:
                print(f"ğŸ¤ å®æ—¶è¯†åˆ«ä¸­: {result}")
        except json.JSONDecodeError:
            print(f"âŒ JSONè§£æå¤±è´¥: {message}")

    def on_completed(self, message, *args):
        print(f"ğŸ”§ DEBUG: on_completed è¢«è°ƒç”¨: {message}")

    def on_error(self, message, *args):
        print(f"âŒ é˜¿é‡Œäº‘è¯†åˆ«é”™è¯¯: {message}")
        print(f"âŒ é”™è¯¯å‚æ•°: {args}")

    def on_close(self, *args):
        print(f"ğŸ”§ DEBUG: on_close è¢«è°ƒç”¨: {args}")


# è°ƒç”¨é˜¿é‡Œäº‘çš„è¯­éŸ³è½¬æ–‡å­—çš„æ¥å£
def recognize_speech(audio_data, recognizer):
    # print(f"ğŸ”§ DEBUG: recognize_speech è¢«è°ƒç”¨ï¼ŒéŸ³é¢‘æ•°æ®é•¿åº¦: {len(audio_data)}")
    try:
        audio_data = np.concatenate(audio_data)
        audio_bytes = audio_data.tobytes()
        # print(f"ğŸ”§ DEBUG: éŸ³é¢‘æ•°æ®è½¬æ¢å®Œæˆï¼Œå­—èŠ‚é•¿åº¦: {len(audio_bytes)}")
        recognizer.send_audio(audio_bytes)
        # print(f"âœ… éŸ³é¢‘æ•°æ®å·²å‘é€åˆ°é˜¿é‡Œäº‘")
    except Exception as e:
        print(f"âŒ recognize_speech å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


# å¼€å¯éŸ³é¢‘æµå¹¶å¤„ç†éŸ³é¢‘æ•°æ®
def start_audio_stream(recognizer, mic_device_index=1):
    # print(f"ğŸ”§ DEBUG: start_audio_stream è¢«è°ƒç”¨ï¼Œmic_device_index={mic_device_index}")
    global RUNNING
    with running_lock:
        RUNNING = True  # è®¾ç½®å…¨å±€å˜é‡RUNNINGä¸ºTrueï¼Œå¼€å¯è¯­éŸ³è¯†åˆ«
        print("âœ… è¯­éŸ³è¯†åˆ«çŠ¶æ€å·²è®¾ä¸ºå¼€å¯")

    def audio_processing():
        print("ğŸ”§ DEBUG: audio_processing çº¿ç¨‹å·²å¯åŠ¨")
        nonlocal recognizer
        mic_audio_buffer = []
        buffer_count = 0

        while True:
            with running_lock:
                if not RUNNING:
                    print("ğŸ›‘ è¯­éŸ³è¯†åˆ«å·²å…³é—­ï¼Œé€€å‡ºéŸ³é¢‘å¤„ç†å¾ªç¯")
                    break

            # å¤„ç†éŸ³é¢‘é˜Ÿåˆ—
            queue_size = audio_queue.qsize()
            # if queue_size > 0:
            #     print(f"ğŸ¤ DEBUG: éŸ³é¢‘é˜Ÿåˆ—ä¸­æœ‰ {queue_size} ä¸ªæ•°æ®åŒ…")
                
            while not audio_queue.empty():
                try:
                    audio_data = audio_queue.get()
                    mic_audio_buffer.append(audio_data)
                    buffer_count += 1
                    # if buffer_count % 20 == 0:  # æ¯20ä¸ªåŒ…æ‰“å°ä¸€æ¬¡
                    #     print(f"ğŸ¤ DEBUG: å·²å¤„ç† {buffer_count} ä¸ªéŸ³é¢‘åŒ…ï¼Œå½“å‰ç¼“å†²åŒºé•¿åº¦: {len(mic_audio_buffer)}")
                except Exception as e:
                    print(f"âŒ å¤„ç†éŸ³é¢‘é˜Ÿåˆ—æ—¶å‡ºé”™: {e}")

            if len(mic_audio_buffer) >= 10:
                # print(f"ğŸ¤ DEBUG: ç¼“å†²åŒºå·²æ»¡({len(mic_audio_buffer)})ï¼Œå¯åŠ¨è¯†åˆ«çº¿ç¨‹")
                try:
                    threading.Thread(target=recognize_speech, args=(mic_audio_buffer.copy(), recognizer)).start()
                    mic_audio_buffer = []  # æ¸…ç©ºç¼“å†²åŒº
                except Exception as e:
                    print(f"âŒ å¯åŠ¨è¯†åˆ«çº¿ç¨‹å¤±è´¥: {e}")

            time.sleep(0.1)

        recognizer.stop_transcription()
        print("ğŸ”§ DEBUG: audio_processing çº¿ç¨‹å·²ç»“æŸ")

    # åˆ›å»ºéº¦å…‹é£è¾“å…¥æµ
    print(f"ğŸ¤ DEBUG: æ­£åœ¨åˆ›å»ºéº¦å…‹é£è¾“å…¥æµï¼Œè®¾å¤‡ç´¢å¼•: {mic_device_index}")
    try:
        # æµ‹è¯•è®¾å¤‡æ˜¯å¦å¯ç”¨
        test_stream = sd.InputStream(
            callback=None,
            channels=1,
            samplerate=16000,
            dtype='int16',
            device=mic_device_index
        )
        test_stream.close()
        print(f"âœ… éº¦å…‹é£è®¾å¤‡ {mic_device_index} æµ‹è¯•æˆåŠŸ")
        
        mic_stream = sd.InputStream(
            callback=audio_callback,
            channels=1,
            samplerate=16000,
            dtype='int16',
            device=mic_device_index
        )
        print("âœ… éº¦å…‹é£è¾“å…¥æµåˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ éº¦å…‹é£è¾“å…¥æµåˆ›å»ºå¤±è´¥: {e}")
        print("ğŸ”§ å°è¯•åˆ—å‡ºå¯ç”¨è®¾å¤‡...")
        list_audio_devices()
        return

    print("ğŸ¤ DEBUG: å¯åŠ¨éŸ³é¢‘æµ...")
    try:
        with mic_stream:
            print("âœ… éº¦å…‹é£å·²æ¿€æ´»ï¼Œå¼€å§‹éŸ³é¢‘å¤„ç†")
            audio_processing()
    except Exception as e:
        print(f"âŒ éŸ³é¢‘æµè¿è¡Œæ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def toggle_audio_stream(enabled: bool):
    print(f"ğŸ”§ DEBUG: toggle_audio_stream è¢«è°ƒç”¨ï¼Œenabled={enabled}")
    print(f"åˆ‡æ¢è¯­éŸ³è¯†åˆ«çŠ¶æ€: {'å¼€å¯' if enabled else 'å…³é—­'}")
    global RUNNING
    with running_lock:
        old_running = RUNNING
        RUNNING = enabled
        print(f"ğŸ”§ DEBUG: RUNNING çŠ¶æ€ä» {old_running} å˜æ›´ä¸º {RUNNING}")
    
    if enabled:
        print("âŒ WARNING: toggle_audio_stream(True) åªè®¾ç½®äº†çŠ¶æ€ï¼Œä½†æ²¡æœ‰å¯åŠ¨éŸ³é¢‘æµï¼")
        print("ğŸ’¡ æç¤º: éœ€è¦è°ƒç”¨ start_audio_stream() æ¥å®é™…å¯åŠ¨éŸ³é¢‘æµå’Œéº¦å…‹é£")


_RTVTT_recognizer = None
_audio_stream_thread = None  # æ–°å¢ï¼šéŸ³é¢‘æµçº¿ç¨‹


def get_RTVTT_recognizer():
    global _RTVTT_recognizer
    if _RTVTT_recognizer is None:
        _RTVTT_recognizer = RealTimeSpeechRecognizer()
    return _RTVTT_recognizer


def is_voice_recognition_running():
    """æ£€æŸ¥è¯­éŸ³è¯†åˆ«æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
    global RUNNING, _audio_stream_thread
    with running_lock:
        # æ£€æŸ¥å…¨å±€çŠ¶æ€å’Œçº¿ç¨‹çŠ¶æ€
        thread_alive = _audio_stream_thread and _audio_stream_thread.is_alive()
        return RUNNING and thread_alive


def list_audio_devices():
    """åˆ—å‡ºå¯ç”¨çš„éŸ³é¢‘è®¾å¤‡"""
    print("ğŸ¤ DEBUG: å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡:")
    try:
        devices = sd.query_devices()
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:  # åªæ˜¾ç¤ºè¾“å…¥è®¾å¤‡
                print(f"  è®¾å¤‡ {i}: {device['name']} (è¾“å…¥é€šé“: {device['max_input_channels']})")
        print(f"ğŸ¤ DEBUG: é»˜è®¤è¾“å…¥è®¾å¤‡: {sd.default.device[0]}")
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢éŸ³é¢‘è®¾å¤‡å¤±è´¥: {e}")


def start_real_time_voice_recognition(mic_device_index=None):
    """å¯åŠ¨å®Œæ•´çš„å®æ—¶è¯­éŸ³è¯†åˆ«ï¼ˆåŒ…æ‹¬éŸ³é¢‘æµï¼‰"""
    print(f"ğŸ”§ DEBUG: start_real_time_voice_recognition è¢«è°ƒç”¨ï¼Œmic_device_index={mic_device_index}")
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè®¾å¤‡ï¼Œä½¿ç”¨é»˜è®¤è®¾å¤‡
    if mic_device_index is None:
        try:
            mic_device_index = sd.default.device[0]
            print(f"ğŸ¤ ä½¿ç”¨é»˜è®¤éº¦å…‹é£è®¾å¤‡: {mic_device_index}")
        except:
            mic_device_index = 0
            print(f"ğŸ¤ ä½¿ç”¨è®¾å¤‡ 0 ä½œä¸ºé»˜è®¤è®¾å¤‡")
    
    # åˆ—å‡ºå¯ç”¨è®¾å¤‡ä»¥ä¾›è°ƒè¯•
    list_audio_devices()
    
    global _audio_stream_thread, RUNNING
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨è¿è¡Œ
    if _audio_stream_thread and _audio_stream_thread.is_alive():
        print("âš ï¸ è¯­éŸ³è¯†åˆ«å·²åœ¨è¿è¡Œä¸­")
        return True
    
    try:
        # è·å–è¯†åˆ«å™¨å¹¶å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–transcriber
        recognizer = get_RTVTT_recognizer()
        
        # é‡è¦ï¼šå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–transcriberï¼Œç¡®ä¿æ¯æ¬¡å¯åŠ¨éƒ½æ˜¯å…¨æ–°çš„
        print("ğŸ”§ å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–é˜¿é‡Œäº‘transcriber...")
        recognizer._RealTimeSpeechRecognizer__initialize_transcriber()
        print("âœ… é˜¿é‡Œäº‘transcriberé‡æ–°åˆå§‹åŒ–å®Œæˆ")
        
        # ã€æ–°å¢ã€‘å¯åŠ¨å‰æ¸…ç©ºè¯†åˆ«å†…å®¹ï¼Œç¡®ä¿é‡æ–°å¼€å§‹
        recognizer.last_complete_sentence = ""
        recognizer.current_text = ""
        print("ğŸ§¹ è¯†åˆ«å™¨å†…å®¹å·²æ¸…ç©ºï¼Œç¡®ä¿é‡æ–°å¼€å§‹")
        print("âœ… è¯­éŸ³è¯†åˆ«å™¨å·²å‡†å¤‡å°±ç»ª")
        
        # å¯åŠ¨éŸ³é¢‘æµçº¿ç¨‹
        print("ğŸš€ æ­£åœ¨å¯åŠ¨éŸ³é¢‘æµçº¿ç¨‹...")
        _audio_stream_thread = threading.Thread(
            target=start_audio_stream,
            args=(recognizer, mic_device_index),
            daemon=True
        )
        _audio_stream_thread.start()
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿çº¿ç¨‹å¯åŠ¨
        time.sleep(0.5)
        
        if _audio_stream_thread.is_alive():
            print("âœ… å®æ—¶è¯­éŸ³è¯†åˆ«å®Œå…¨å¯åŠ¨æˆåŠŸï¼")
            print(f"ğŸ¤ éº¦å…‹é£è®¾å¤‡ç´¢å¼•: {mic_device_index}")
            print(f"ğŸ”§ RUNNINGçŠ¶æ€: {RUNNING}")
            return True
        else:
            print("âŒ éŸ³é¢‘æµçº¿ç¨‹å¯åŠ¨å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ å¯åŠ¨å®æ—¶è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def stop_real_time_voice_recognition():
    """åœæ­¢å®æ—¶è¯­éŸ³è¯†åˆ«"""
    print("ğŸ”§ DEBUG: stop_real_time_voice_recognition è¢«è°ƒç”¨")
    global _audio_stream_thread, RUNNING, _RTVTT_recognizer
    
    # å…ˆåœæ­¢transcriber
    if _RTVTT_recognizer and _RTVTT_recognizer.transcriber:
        try:
            print("ğŸ”§ æ­£åœ¨åœæ­¢é˜¿é‡Œäº‘transcriber...")
            _RTVTT_recognizer.transcriber.stop()
            print("âœ… é˜¿é‡Œäº‘transcriberå·²åœæ­¢")
        except Exception as e:
            print(f"âš ï¸ åœæ­¢transcriberæ—¶å‡ºé”™: {e}")
    
    # åœæ­¢éŸ³é¢‘æµ
    with running_lock:
        RUNNING = False
        print(f"ğŸ”§ DEBUG: RUNNING è®¾ç½®ä¸º False")
    
    # ç­‰å¾…çº¿ç¨‹ç»“æŸ
    if _audio_stream_thread and _audio_stream_thread.is_alive():
        print("â³ ç­‰å¾…éŸ³é¢‘æµçº¿ç¨‹ç»“æŸ...")
        _audio_stream_thread.join(timeout=3.0)
        if _audio_stream_thread.is_alive():
            print("âš ï¸ éŸ³é¢‘æµçº¿ç¨‹æœªèƒ½æ­£å¸¸ç»“æŸ")
        else:
            print("âœ… éŸ³é¢‘æµçº¿ç¨‹å·²ç»“æŸ")
    
    _audio_stream_thread = None
    
    # é‡è¦ï¼šæ¸…ç©ºå’Œé‡ç½®è¯†åˆ«å™¨ï¼Œå‡†å¤‡ä¸‹æ¬¡ä½¿ç”¨
    if _RTVTT_recognizer is not None:
        print("ğŸ”§ æ­£åœ¨é‡ç½®è¯­éŸ³è¯†åˆ«å™¨...")
        _RTVTT_recognizer.last_complete_sentence = ""
        _RTVTT_recognizer.current_text = ""
        _RTVTT_recognizer.transcriber = None  # æ¸…ç©ºtranscriberï¼Œå¼ºåˆ¶ä¸‹æ¬¡é‡æ–°åˆå§‹åŒ–
        print("âœ… è¯­éŸ³è¯†åˆ«å™¨å·²é‡ç½®")
    
    print("âœ… å®æ—¶è¯­éŸ³è¯†åˆ«å·²å®Œå…¨åœæ­¢")

if __name__ == "__main__":
    # é»˜è®¤éº¦å…‹é£
    mic_device_index = 1

    # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
    recognizer = RealTimeSpeechRecognizer(URL, TOKEN, APPKEY)
    # å¼€å¯éŸ³é¢‘æµå¹¶å¤„ç†éŸ³é¢‘æ•°æ®
    start_audio_stream(recognizer, mic_device_index)
