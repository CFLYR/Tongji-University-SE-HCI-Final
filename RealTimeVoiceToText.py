import time
import queue
import sounddevice as sd
import numpy as np
import nls
import sys
import threading
import json
from ppt_controller import get_ppt_controller
import re

# é˜¿é‡Œäº‘é…ç½®ä¿¡æ¯
URL = "wss://nls-gateway-cn-shanghai.aliyuncs.com/ws/v1"
TOKEN = "51e5f05a6fe84b6f835bfc301aa78369"  # å®é™…Tokenï¼Œè¿™æ˜¯ä¸´æ—¶çš„å…è´¹çš„ï¼Œå¯èƒ½éœ€è¦æ¯24å°æ—¶æ¢ä¸€ä¸ª
APPKEY = "eb0qKUAXtcStGTtw"  # å®é™…Appkey

# è®°å½•éŸ³é¢‘æ•°æ®çš„é˜Ÿåˆ—
audio_queue = queue.Queue()

# æ§åˆ¶è¯­éŸ³è¯†åˆ«çš„å¼€å¯å’Œå…³é—­
RUNNING: bool = False
running_lock = threading.Lock()  # ç”¨äºä¿æŠ¤RUNNINGå˜é‡çš„é”
page_lock = threading.Lock()  # ç¿»é¡µé”

output_lock = threading.Lock()


# ä»éº¦å…‹é£è¾“å…¥éŸ³é¢‘çš„å›è°ƒå‡½æ•° å‘éŸ³é¢‘é˜Ÿåˆ—ä¸­æ·»åŠ æ•°æ®
def audio_callback(indata, frames, time, status):
    if status:
        ## print(
        x=1
    # æ·»åŠ ç®€å•çš„éŸ³é¢‘æ´»åŠ¨æ£€æµ‹
    volume = np.sqrt(np.mean(indata**2))
    if volume > 0.01:  # å¦‚æœæœ‰è¶³å¤Ÿçš„éŸ³é¢‘ä¿¡å·
        ## print(
        x=1
    audio_queue.put(indata.copy())


class RealTimeSpeechRecognizer:
    def __init__(self, url=URL, token=TOKEN, appkey=APPKEY):
        self.url = url
        self.token = token
        self.appkey = appkey
        self.transcriber = None
        self.current_text = ""  # å­˜å‚¨å½“å‰è¯†åˆ«çš„æ–‡æœ¬
        self.last_complete_sentence = ""  # å­˜å‚¨æœ€åå®Œæˆçš„å¥å­
        self.__initialize_transcriber()

        # æ¢é¡µå…³é”®è¯
        self.next_page_keywords = []
        self.prev_page_keyword = "ä¸Šä¸€é¡µ"
    def __initialize_transcriber(self):
        # print(
        # print(
        # print(
        # print( # åªæ˜¾ç¤ºå‰20ä¸ªå­—ç¬¦
        
        try:
            self.transcriber = nls.NlsSpeechTranscriber(
                url=self.url,
                token=self.token,
                appkey=self.appkey,
                on_sentence_begin=self.on_sentence_begin,
                on_sentence_end=self.on_sentence_end,
                on_start=self.on_start,
                on_result_changed=self.on_result_changed,
                on_completed=self.on_completed,
                on_error=self.on_error,
                on_close=self.on_close
            )
            # print(
            
            self.transcriber.start(aformat="pcm",
                                   enable_intermediate_result=True,
                                   enable_punctuation_prediction=True,
                                   enable_inverse_text_normalization=True)
            # print(
        except Exception as e:
            # print(
            import traceback
            traceback.print_exc()

    def send_audio(self, audio_data):
        if self.transcriber:
            self.transcriber.send_audio(audio_data)

    def stop_transcription(self):
        if self.transcriber:
            self.transcriber.stop()

    def get_current_text(self):
        """è·å–å½“å‰è¯†åˆ«çš„æ–‡æœ¬"""
        return self.current_text

    def get_last_complete_sentence(self):
        """è·å–æœ€åå®Œæˆçš„å¥å­"""
        return self.last_complete_sentence

    def on_sentence_begin(self, message, *args):
        # è§£æJSONæ¶ˆæ¯
        try:
            data = json.loads(message)
            result = data.get('payload', {}).get('result', '')
            self.current_text = result
            # with output_lock:
            #     print(f"\n[å¼€å§‹] {result}")
        except json.JSONDecodeError:
            # print(f"è§£æé”™è¯¯: {message}")
            pass

    def detect_page_jump_command(self, text):
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹è·³è½¬é¡µé¢æŒ‡ä»¤
        æ”¯æŒä¸­è‹±æ–‡æ··åˆè¡¨è¾¾ï¼Œå¦‚ï¼š
          "è·³è½¬åˆ°ç¬¬5é¡µ"
          "go to page 10"
          "ç¿»åˆ°ç¬¬3é¡µ"
          "jump to page 15"
        """
        # ç»Ÿä¸€è½¬æ¢ä¸ºå°å†™ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        normalized_text = text.lower()
        # å®šä¹‰è·³è½¬é¡µé¢çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        # ä¸­æ–‡æ¨¡å¼ï¼šåŒ¹é… "è·³è½¬[åˆ°/è‡³]ç¬¬Xé¡µ" æˆ– "ç¿»åˆ°ç¬¬Xé¡µ"
        chinese_pattern = r'(?:è·³è½¬|ç¿»|è½¬åˆ°|åˆ‡æ¢)[åˆ°è‡³]?ç¬¬?(\d+)[é¡µå¼ ]'
        # è‹±æ–‡æ¨¡å¼ï¼šåŒ¹é… "go to page X" æˆ– "jump to page X"
        english_pattern = r'(?:go|jump|switch)\s*to\s*page\s*(\d+)'
        # ç»„åˆä¸­è‹±æ–‡æ¨¡å¼
        combined_pattern = f"({chinese_pattern})|({english_pattern})"
        # åœ¨æ–‡æœ¬ä¸­æœç´¢åŒ¹é…
        match = re.search(combined_pattern, normalized_text)
        if match:
            # æå–é¡µç æ•°å­—ï¼ˆä¼˜å…ˆå–ä¸­æ–‡åŒ¹é…ï¼Œå¦‚æœæ²¡æœ‰åˆ™å–è‹±æ–‡åŒ¹é…ï¼‰
            page_num = match.group(1) or match.group(3)
            if page_num:
                try:
                    page_num = int(page_num)
                    # æ‰§è¡Œè·³è½¬æ“ä½œ
                    get_ppt_controller().jump_to_slide(page_num)
                except ValueError:
                    # print(f"æå–çš„é¡µç æ— æ•ˆ: {page_num}")
                    pass   
                
    def on_sentence_end(self, message, *args):
        # è§£æJSONæ¶ˆæ¯
        try:
            data = json.loads(message)
            result = data.get('payload', {}).get('result', '')
            self.current_text = ""
            self.last_complete_sentence = result  # ä¸€å¥å®Œæ•´çš„ä¸ä¸­æ–­çš„è¯
            
            print(f"\nğŸ”§ DEBUG: on_sentence_end æ”¶åˆ°å®Œæ•´å¥å­: '{result}'")
            # print(
            # print(
            
            # å½“ä¸€æ®µè¿ç»­ä¸ä¸­æ–­çš„è¯ç»“æŸ é˜¿é‡Œäº‘çš„sdkä¼šè‡ªåŠ¨è°ƒç”¨è¯¥å‡½æ•° åœ¨è¿™é‡Œè°ƒç”¨PPTæ¢é¡µçš„é€»è¾‘
            with page_lock:                # æ£€æŸ¥ä¸‹ä¸€é¡µå…³é”®è¯
                matched_next_keywords = [kw for kw in self.next_page_keywords if kw in result]
                # print(
                if matched_next_keywords:
                    # print(
                    
                    # ç›´æ¥å‘é€æŒ‰é”®ï¼ŒåŒæ—¶æ¿€æ´»PPTçª—å£
                    try:
                        import pyautogui as pt
                        import time
                        
                        # æ¿€æ´»PPTçª—å£çš„ç®€å•æ–¹æ³•ï¼šå…ˆåˆ‡æ¢çª—å£ï¼Œå†å‘é€æŒ‰é”®
                        pt.FAILSAFE = False
                        pt.PAUSE = 0.1
                        
                        # ä½¿ç”¨Alt+Tabåˆ‡æ¢åˆ°PPTçª—å£
                        pt.hotkey('alt', 'tab')
                        time.sleep(0.2)  # ç­‰å¾…çª—å£åˆ‡æ¢
                        
                        # å‘é€å³ç®­å¤´é”®ï¼ˆä¸‹ä¸€é¡µï¼‰
                        pt.press('right')
                        # print(
                    except Exception as e:
                        # print(
                        # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•ä½¿ç”¨PPTæ§åˆ¶å™¨
                        try:
                            get_ppt_controller().next_slide()
                        except Exception as e2:
                            print("æ‰§è¡Œä¸‹ä¸€é¡µæ“ä½œæ—¶å‡ºé”™:", e2)

                    print(f"ğŸ“„ å·²æ‰§è¡Œä¸‹ä¸€é¡µæ“ä½œ")
                                
                elif self.prev_page_keyword in result:
                    # print(
                    
                    # ç›´æ¥å‘é€æŒ‰é”®ï¼Œä¸ä¾èµ–PPTæ§åˆ¶å™¨çŠ¶æ€
                    try:
                        import pyautogui as pt
                        pt.FAILSAFE = False
                        pt.PAUSE = 0.1
                        pt.press('left')  # å‘é€å·¦ç®­å¤´é”®ï¼ˆä¸Šä¸€é¡µï¼‰
                        # print(
                    except Exception as e:
                        # print(
                        # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•ä½¿ç”¨PPTæ§åˆ¶å™¨
                        try:
                            get_ppt_controller().previous_slide()
                        except Exception as e2:
                            print("æ‰§è¡Œä¸Šä¸€é¡µæ“ä½œæ—¶å‡ºé”™:", e2)

                    print(f"ğŸ“„ å·²æ‰§è¡Œä¸Šä¸€é¡µæ“ä½œ")
                else:
                    # print(
                    # print(
                    self.detect_page_jump_command(result)
                    
            with output_lock:
                print(f"\n[å®Œæ•´å¥å­] {result}")
        except json.JSONDecodeError:
            # print(
            pass
        
    def on_start(self, message, *args):
        print("å¼€å§‹è¯†åˆ«")

    def on_result_changed(self, message, *args):
        # è§£æJSONæ¶ˆæ¯ - è¿™æ˜¯å®æ—¶æ›´æ–°çš„æ–‡æœ¬
        # print(
        try:
            data = json.loads(message)
            result = data.get('payload', {}).get('result', '')
            self.current_text = result
            if result:
                print("å®æ—¶è¯†åˆ«ç»“æœ:", result)
        except json.JSONDecodeError:
            print("è§£æå®æ—¶è¯†åˆ«ç»“æœæ—¶å‡ºé”™:", e)

    def on_completed(self, message, *args):
        print("è¯†åˆ«å®Œæˆ")

    def on_error(self, message, *args):
        # print(
        print("è¯†åˆ«å‡ºé”™:", message)

    def on_close(self, *args):
        print("è¯†åˆ«å…³é—­")


# è°ƒç”¨é˜¿é‡Œäº‘çš„è¯­éŸ³è½¬æ–‡å­—çš„æ¥å£
def recognize_speech(audio_data, recognizer):
    # # print(
    try:
        audio_data = np.concatenate(audio_data)
        audio_bytes = audio_data.tobytes()
        # # print(
        recognizer.send_audio(audio_bytes)
        # # print(
    except Exception as e:
        print("è¯†åˆ«å‡ºé”™:", e)
        import traceback
        traceback.print_exc()


# å¼€å¯éŸ³é¢‘æµå¹¶å¤„ç†éŸ³é¢‘æ•°æ®
def start_audio_stream(recognizer, mic_device_index=1):
    # # print(
    global RUNNING
    with running_lock:
        RUNNING = True  # è®¾ç½®å…¨å±€å˜é‡RUNNINGä¸ºTrueï¼Œå¼€å¯è¯­éŸ³è¯†åˆ«
        # print(

    def audio_processing():
        # print(
        nonlocal recognizer
        mic_audio_buffer = []
        buffer_count = 0

        while True:
            with running_lock:
                if not RUNNING:
                    # print(
                    break

            # å¤„ç†éŸ³é¢‘é˜Ÿåˆ—
            queue_size = audio_queue.qsize()
            # if queue_size > 0:
            #     # print(
                
            while not audio_queue.empty():
                try:
                    audio_data = audio_queue.get()
                    mic_audio_buffer.append(audio_data)
                    buffer_count += 1
                    # if buffer_count % 20 == 0:  # æ¯20ä¸ªåŒ…æ‰“å°ä¸€æ¬¡
                    #     # print(
                except Exception as e:
                    print("å¤„ç†éŸ³é¢‘é˜Ÿåˆ—æ—¶å‡ºé”™:", e)

            if len(mic_audio_buffer) >= 10:
                # # print(
                try:
                    threading.Thread(target=recognize_speech, args=(mic_audio_buffer.copy(), recognizer)).start()
                    mic_audio_buffer = []  # æ¸…ç©ºç¼“å†²åŒº
                except Exception as e:
                    print("å¤„ç†éŸ³é¢‘ç¼“å†²åŒºæ—¶å‡ºé”™:", e)

            time.sleep(0.1)

        recognizer.stop_transcription()
        # print(

    # åˆ›å»ºéº¦å…‹é£è¾“å…¥æµ
    # print(
    try:
        # æµ‹è¯•è®¾å¤‡æ˜¯å¦å¯ç”¨
        test_stream = sd.InputStream(
            callback=None,
            channels=1,
            samplerate=16000,
            dtype='int16',
            device=mic_device_index
        )
        test_stream.close()
        # print(
        
        mic_stream = sd.InputStream(
            callback=audio_callback,
            channels=1,
            samplerate=16000,
            dtype='int16',
            device=mic_device_index
        )
        # print(
    except Exception as e:
        # print(
        # print(
        list_audio_devices()
        return

    # print(
    try:
        with mic_stream:
            # print(
            audio_processing()
    except Exception as e:
        # print(
        import traceback
        traceback.print_exc()


def toggle_audio_stream(enabled: bool):
    # print(
    print(f"åˆ‡æ¢è¯­éŸ³è¯†åˆ«çŠ¶æ€: {'å¼€å¯' if enabled else 'å…³é—­'}")
    global RUNNING
    with running_lock:
        old_running = RUNNING
        RUNNING = enabled
        # print(
    
    # if enabled:
    #     # print(
    #     # print(


_RTVTT_recognizer = None
_audio_stream_thread = None  # æ–°å¢ï¼šéŸ³é¢‘æµçº¿ç¨‹


def get_RTVTT_recognizer():
    global _RTVTT_recognizer
    if _RTVTT_recognizer is None:
        _RTVTT_recognizer = RealTimeSpeechRecognizer()
    return _RTVTT_recognizer


def is_voice_recognition_running():
    """æ£€æŸ¥è¯­éŸ³è¯†åˆ«æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
    global RUNNING, _audio_stream_thread
    with running_lock:
        # æ£€æŸ¥å…¨å±€çŠ¶æ€å’Œçº¿ç¨‹çŠ¶æ€
        thread_alive = _audio_stream_thread and _audio_stream_thread.is_alive()
        return RUNNING and thread_alive


def list_audio_devices():
    """åˆ—å‡ºå¯ç”¨çš„éŸ³é¢‘è®¾å¤‡"""
    # print(
    try:
        devices = sd.query_devices()
        # for i, device in enumerate(devices):
        #     if device['max_input_channels'] > 0:  # åªæ˜¾ç¤ºè¾“å…¥è®¾å¤‡
        #         print(f"  è®¾å¤‡ {i}: {device['name']} (è¾“å…¥é€šé“: {device['max_input_channels']})")
        # print(
    except Exception as e:
        print("åˆ—å‡ºéŸ³é¢‘è®¾å¤‡æ—¶å‡ºé”™:", e)


def start_real_time_voice_recognition(mic_device_index=None):
    """å¯åŠ¨å®Œæ•´çš„å®æ—¶è¯­éŸ³è¯†åˆ«ï¼ˆåŒ…æ‹¬éŸ³é¢‘æµï¼‰"""
    # print(
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè®¾å¤‡ï¼Œä½¿ç”¨é»˜è®¤è®¾å¤‡
    if mic_device_index is None:
        try:
            mic_device_index = sd.default.device[0]
            # print(
        except:
            mic_device_index = 0
            # print(
    
    # åˆ—å‡ºå¯ç”¨è®¾å¤‡ä»¥ä¾›è°ƒè¯•
    list_audio_devices()
    
    global _audio_stream_thread, RUNNING
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨è¿è¡Œ
    if _audio_stream_thread and _audio_stream_thread.is_alive():
        # print(
        return True
    
    try:
        # è·å–è¯†åˆ«å™¨å¹¶å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–transcriber
        recognizer = get_RTVTT_recognizer()
        
        # é‡è¦ï¼šå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–transcriberï¼Œç¡®ä¿æ¯æ¬¡å¯åŠ¨éƒ½æ˜¯å…¨æ–°çš„
        # print(
        recognizer._RealTimeSpeechRecognizer__initialize_transcriber()
        # print(
        
        # ã€æ–°å¢ã€‘å¯åŠ¨å‰æ¸…ç©ºè¯†åˆ«å†…å®¹ï¼Œç¡®ä¿é‡æ–°å¼€å§‹
        recognizer.last_complete_sentence = ""
        recognizer.current_text = ""
        # print(
        # print(
        
        # å¯åŠ¨éŸ³é¢‘æµçº¿ç¨‹
        # print(
        _audio_stream_thread = threading.Thread(
            target=start_audio_stream,
            args=(recognizer, mic_device_index),
            daemon=True
        )
        _audio_stream_thread.start()
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿çº¿ç¨‹å¯åŠ¨
        time.sleep(0.5)
        
        if _audio_stream_thread.is_alive():
            # print(
            # print(
            # print(
            return True
        else:
            # print(
            return False
            
    except Exception as e:
        # print(
        import traceback
        traceback.print_exc()
        return False


def stop_real_time_voice_recognition():
    """åœæ­¢å®æ—¶è¯­éŸ³è¯†åˆ«"""
    # print(
    global _audio_stream_thread, RUNNING, _RTVTT_recognizer
    
    # å…ˆåœæ­¢transcriber
    if _RTVTT_recognizer and _RTVTT_recognizer.transcriber:
        try:
            # print(
            _RTVTT_recognizer.transcriber.stop()
            # print(
        except Exception as e:
            print("åœæ­¢transcriberæ—¶å‡ºé”™:", e)

    # åœæ­¢éŸ³é¢‘æµ
    with running_lock:
        RUNNING = False
        # print(
    
    # ç­‰å¾…çº¿ç¨‹ç»“æŸ
    if _audio_stream_thread and _audio_stream_thread.is_alive():
        print("â³ ç­‰å¾…éŸ³é¢‘æµçº¿ç¨‹ç»“æŸ...")
        _audio_stream_thread.join(timeout=3.0)
        # if _audio_stream_thread.is_alive():
        #     # print(
        # else:
        #     # print(
    
    _audio_stream_thread = None
    
    # é‡è¦ï¼šæ¸…ç©ºå’Œé‡ç½®è¯†åˆ«å™¨ï¼Œå‡†å¤‡ä¸‹æ¬¡ä½¿ç”¨
    if _RTVTT_recognizer is not None:
        # print(
        _RTVTT_recognizer.last_complete_sentence = ""
        _RTVTT_recognizer.current_text = ""
        _RTVTT_recognizer.transcriber = None  # æ¸…ç©ºtranscriberï¼Œå¼ºåˆ¶ä¸‹æ¬¡é‡æ–°åˆå§‹åŒ–
        # print(
    
    # print(

def set_voice_keywords(next_page_keywords: list, prev_page_keyword: str = "ä¸Šä¸€é¡µ"):
    """è®¾ç½®è¯­éŸ³è¯†åˆ«çš„å…³é”®è¯"""
    global _RTVTT_recognizer
    
    # print(
    # print(
    # print(
    
    # è·å–æˆ–åˆ›å»ºè¯†åˆ«å™¨
    recognizer = get_RTVTT_recognizer()
    
    # è®¾ç½®å…³é”®è¯
    recognizer.next_page_keywords = next_page_keywords.copy() if next_page_keywords else []
    recognizer.prev_page_keyword = prev_page_keyword
    
    # print(
    print(f"   - ä¸‹ä¸€é¡µå…³é”®è¯: {recognizer.next_page_keywords}")
    print(f"   - ä¸Šä¸€é¡µå…³é”®è¯: '{recognizer.prev_page_keyword}'")

def get_voice_keywords():
    """è·å–å½“å‰è®¾ç½®çš„è¯­éŸ³å…³é”®è¯"""
    global _RTVTT_recognizer
    
    if _RTVTT_recognizer is None:
        return [], "ä¸Šä¸€é¡µ"
    
    return _RTVTT_recognizer.next_page_keywords.copy(), _RTVTT_recognizer.prev_page_keyword

if __name__ == "__main__":
    # é»˜è®¤éº¦å…‹é£
    mic_device_index = 1

    # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
    recognizer = RealTimeSpeechRecognizer(URL, TOKEN, APPKEY)
    # å¼€å¯éŸ³é¢‘æµå¹¶å¤„ç†éŸ³é¢‘æ•°æ®
    start_audio_stream(recognizer, mic_device_index)
