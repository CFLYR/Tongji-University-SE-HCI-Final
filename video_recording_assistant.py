 
"""
å½•è§†é¢‘åŠ©æ‰‹ - Video Recording Assistant

åŠŸèƒ½ç‰¹æ€§:
1. å½•åˆ¶å½“å‰å±å¹•å†…å®¹
2. å¯é€‰æ‹©æ˜¯å¦å¼€å¯å‰ç½®æ‘„åƒå¤´
3. å¯é€‰æ‹©æ˜¯å¦å½•åˆ¶éº¦å…‹é£
4. å¯é€‰æ‹©æ˜¯å¦å¼€å¯AIæ¼”è®²å­—å¹•
5. å¯é€‰æ‹©æ˜¯å¦æ ¹æ®å¯¼å…¥æ¼”è®²æ–‡ç¨¿ä¿®æ­£AIå­—å¹•
6. æ‰‹åŠ¨ä¿®æ”¹è§†é¢‘æ¼”è®²å­—å¹•
7. æ¼”è®²å­—å¹•å¯¼å‡ºåŠŸèƒ½
8. æ¼”è®²å­—å¹•æ–‡ä»¶è¯»å–åŠŸèƒ½
"""
import RealTimeVoiceToText as RTVTT
import cv2 as cv
import numpy as np
import pyaudio
import wave
import threading
import time
import json
import os
import subprocess
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Callable
from dataclasses import dataclass, asdict
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import speech_recognition as sr
import pyttsx3
from PIL import Image, ImageTk
import mss
import ffmpeg
# å¯¼å…¥ç°æœ‰æ¨¡å—
from speech_text_manager import SpeechTextManager, TextMatcher
from chinese_text_renderer import put_text_auto


@dataclass
class SubtitleSegment:
    """å­—å¹•ç‰‡æ®µæ•°æ®ç»“æ„"""
    start_time: float  # å¼€å§‹æ—¶é—´(ç§’)
    end_time: float  # ç»“æŸæ—¶é—´(ç§’)
    text: str  # å­—å¹•æ–‡æœ¬
    corrected_text: str = ""  # ä¿®æ­£åçš„æ–‡æœ¬
    confidence: float = 0.0  # è¯†åˆ«ç½®ä¿¡åº¦
    is_corrected: bool = False  # æ˜¯å¦å·²ä¿®æ­£


@dataclass
class RecordingConfig:
    """å½•åˆ¶é…ç½®"""
    enable_screen: bool = True  # å½•åˆ¶å±å¹•
    enable_camera: bool = False  # å½•åˆ¶æ‘„åƒå¤´
    enable_microphone: bool = True  # å½•åˆ¶éº¦å…‹é£
    enable_ai_subtitles: bool = True  # å¼€å¯AIå­—å¹•
    enable_script_correction: bool = False  # å¼€å¯æ–‡ç¨¿ä¿®æ­£
    record_floating_window: bool = False  # å½•åˆ¶æ‚¬æµ®çª—å†…å®¹
    output_dir: str = "recordings"  # è¾“å‡ºç›®å½•
    video_fps: int = 30  # è§†é¢‘å¸§ç‡
    audio_sample_rate: int = 44100  # éŸ³é¢‘é‡‡æ ·ç‡
    camera_position: str = "bottom_right"  # æ‘„åƒå¤´ä½ç½® 
    camera_size: tuple = (320, 240)  # æ‘„åƒå¤´å¤§å°


class AudioRecorder:
    """éŸ³é¢‘å½•åˆ¶å™¨"""

    def __init__(self, config: RecordingConfig):
        self.config = config
        self.is_recording = False
        self.audio_data = []
        self.audio_thread = None

        # éŸ³é¢‘é…ç½®
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = config.audio_sample_rate
        self.chunk = 1024

        self.audio = pyaudio.PyAudio()
        self.stream = None

    def start_recording(self):
        """å¼€å§‹å½•åˆ¶éŸ³é¢‘"""
        if self.is_recording:
            return

        self.is_recording = True
        self.audio_data = []

        try:
            self.stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )

            self.audio_thread = threading.Thread(target=self._record_audio)
            self.audio_thread.start()
            #print("ğŸµ å¼€å§‹å½•åˆ¶éŸ³é¢‘")

        except Exception as e:
            # print(
            self.is_recording = False

    def _record_audio(self):
        """å½•åˆ¶éŸ³é¢‘çº¿ç¨‹"""
        while self.is_recording:
            try:
                data = self.stream.read(self.chunk, exception_on_overflow=False)
                self.audio_data.append(data)
            except Exception as e:
                # print(
                break

    def stop_recording(self, output_path: str):
        """åœæ­¢å½•åˆ¶å¹¶ä¿å­˜éŸ³é¢‘"""
        if not self.is_recording:
            return

        self.is_recording = False

        if self.audio_thread:
            self.audio_thread.join()

        if self.stream:
            self.stream.stop_stream()
            self.stream.close()

        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        wf = wave.open(output_path, 'wb')
        wf.setnchannels(self.channels)
        wf.setsampwidth(self.audio.get_sample_size(self.format))
        wf.setframerate(self.rate)
        wf.writeframes(b''.join(self.audio_data))
        wf.close()
        #print(f"ğŸµ éŸ³é¢‘å·²ä¿å­˜: {output_path}")

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.stream:
            self.stream.close()
        self.audio.terminate()


class VideoRecorder:
    """è§†é¢‘å½•åˆ¶å™¨"""

    def __init__(self, config: RecordingConfig, floating_window=None):
        self.config = config
        self.floating_window = floating_window  # æ‚¬æµ®çª—å¯¹è±¡ï¼Œç”¨äºè·å–çª—å£ä½ç½®
        self.is_recording = False
        self.screen_capture = None
        self.camera_capture = None
        self.video_writer = None
        self.recording_thread = None
        self.start_time = None

    def initialize_captures(self):
        """åˆå§‹åŒ–æ•è·è®¾å¤‡"""
        # åˆå§‹åŒ–å±å¹•æ•è·
        if self.config.enable_screen:
            try:
                self.screen_capture = mss.mss()
                self.monitor = self.screen_capture.monitors[1]  # ä¸»æ˜¾ç¤ºå™¨
                # print(
            except Exception as e:
                # print(
                self.config.enable_screen = False

        # åˆå§‹åŒ–æ‘„åƒå¤´
        if self.config.enable_camera:
            try:
                self.camera_capture = cv.VideoCapture(0)
                if not self.camera_capture.isOpened():
                    # print(
                    self.config.enable_camera = False
                else:
                    self.camera_capture.set(cv.CAP_PROP_FRAME_WIDTH, self.config.camera_size[0])
                    self.camera_capture.set(cv.CAP_PROP_FRAME_HEIGHT, self.config.camera_size[1])
                    # print(
            except Exception as e:
                # print(
                self.config.enable_camera = False

    def start_recording(self, output_path: str):
        """å¼€å§‹å½•åˆ¶è§†é¢‘"""
        if self.is_recording:
            return

        self.initialize_captures()

        # è·å–å±å¹•å°ºå¯¸
        if self.config.enable_screen:
            screen_width = self.monitor["width"]
            screen_height = self.monitor["height"]
        else:
            screen_width, screen_height = 1920, 1080  # é»˜è®¤å°ºå¯¸

        # åˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨
        fourcc = cv.VideoWriter_fourcc(*'mp4v')
        self.video_writer = cv.VideoWriter(
            output_path,
            fourcc,
            self.config.video_fps,
            (screen_width, screen_height)
        )

        if not self.video_writer.isOpened():
            # print(
            return

        self.is_recording = True
        self.start_time = time.time()

        self.recording_thread = threading.Thread(target=self._record_video)
        self.recording_thread.start()
        # print(

    def _record_video(self):
        """å½•åˆ¶è§†é¢‘çº¿ç¨‹"""
        # åœ¨å½•åˆ¶çº¿ç¨‹ä¸­é‡æ–°åˆå§‹åŒ–msså®ä¾‹ä»¥é¿å…çº¿ç¨‹å®‰å…¨é—®é¢˜
        if self.config.enable_screen:
            thread_screen_capture = mss.mss()
            thread_monitor = thread_screen_capture.monitors[1]
        else:
            thread_screen_capture = None
            thread_monitor = None

        while self.is_recording:
            try:
                frame = self._capture_frame_threaded(thread_screen_capture, thread_monitor)
                if frame is not None:
                    self.video_writer.write(frame)
                time.sleep(1.0 / self.config.video_fps)
            except Exception as e:
                # print(
                break

        # æ¸…ç†çº¿ç¨‹æœ¬åœ°çš„screen capture
        if thread_screen_capture:
            thread_screen_capture.close()

    def _capture_frame(self):
        """æ•è·ä¸€å¸§ç”»é¢"""
        frame = None

        # æ•è·å±å¹•
        if self.config.enable_screen:
            try:
                screenshot = self.screen_capture.grab(self.monitor)
                frame = np.array(screenshot)
                frame = cv.cvtColor(frame, cv.COLOR_BGRA2BGR)
            except Exception as e:
                # print(
                # åˆ›å»ºé»‘è‰²ç”»é¢ä½œä¸ºå¤‡ç”¨
                frame = np.zeros((1080, 1920, 3), dtype=np.uint8)

        # æ·»åŠ æ‘„åƒå¤´ç”»é¢
        if self.config.enable_camera and self.camera_capture:
            ret, camera_frame = self.camera_capture.read()
            if ret:
                frame = self._overlay_camera(frame, camera_frame)

        return frame

    def _capture_frame_threaded(self, thread_screen_capture, thread_monitor):
        """çº¿ç¨‹å®‰å…¨çš„å¸§æ•è·æ–¹æ³•"""
        frame = None

        # æ•è·å±å¹•
        if self.config.enable_screen and thread_screen_capture:
            try:
                screenshot = thread_screen_capture.grab(thread_monitor)
                frame = np.array(screenshot)
                frame = cv.cvtColor(frame, cv.COLOR_BGRA2BGR)

                # å¦‚æœä¸å½•åˆ¶æ‚¬æµ®çª—å†…å®¹ï¼Œéœ€è¦é®ç›–æ‚¬æµ®çª—åŒºåŸŸ
                if not self.config.record_floating_window and self.floating_window:
                    frame = self._mask_floating_window(frame)

            except Exception as e:
                # print(
                # åˆ›å»ºé»‘è‰²ç”»é¢ä½œä¸ºå¤‡ç”¨
                frame = np.zeros((1080, 1920, 3), dtype=np.uint8)
                cv.putText(frame, "Screen Capture Error", (50, 100),
                           cv.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)

        # æ·»åŠ æ‘„åƒå¤´ç”»é¢
        if self.config.enable_camera and self.camera_capture:
            ret, camera_frame = self.camera_capture.read()
            if ret:
                frame = self._overlay_camera(frame, camera_frame)
            

        return frame

    def _overlay_camera(self, screen_frame, camera_frame):
        """åœ¨å±å¹•ç”»é¢ä¸Šå åŠ æ‘„åƒå¤´ç”»é¢"""
        if screen_frame is None:
            return camera_frame

        h, w = screen_frame.shape[:2]
        cam_h, cam_w = self.config.camera_size

        # è°ƒæ•´æ‘„åƒå¤´ç”»é¢å¤§å°
        camera_resized = cv.resize(camera_frame, (cam_w, cam_h))

        # æ ¹æ®é…ç½®ä½ç½®æ”¾ç½®æ‘„åƒå¤´ç”»é¢
        if self.config.camera_position == "bottom_right":
            x, y = w - cam_w - 20, h - cam_h - 20
        elif self.config.camera_position == "bottom_left":
            x, y = 20, h - cam_h - 20
        elif self.config.camera_position == "top_right":
            x, y = w - cam_w - 20, 20
        elif self.config.camera_position == "top_left":
            x, y = 20, 20
        else:
            x, y = w - cam_w - 20, h - cam_h - 20  # é»˜è®¤å³ä¸‹è§’
        # å åŠ æ‘„åƒå¤´ç”»é¢
        screen_frame[y:y + cam_h, x:x + cam_w] = camera_resized
        return screen_frame

    def _mask_floating_window(self, frame):

        """é®ç›–æ‚¬æµ®çª—åŒºåŸŸ"""
        if not self.floating_window:
            return frame
        
        return frame

    def stop_recording(self):
        """åœæ­¢å½•åˆ¶è§†é¢‘"""
        if not self.is_recording:
            return

        self.is_recording = False

        if self.recording_thread:
            self.recording_thread.join()

        if self.video_writer:
            self.video_writer.release()

        if self.camera_capture:
            self.camera_capture.release()

        # print(

    def get_recording_duration(self):
        """è·å–å½•åˆ¶æ—¶é•¿"""
        if self.start_time:
            return time.time() - self.start_time
        return 0


class SpeechRecognizer:
    """è¯­éŸ³è¯†åˆ«å™¨"""

    def __init__(self, config: RecordingConfig):
        self.config = config
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        self.is_recognizing = False
        self.recognition_thread = None
        self.subtitles = []
        self.speech_manager = None
        self.text_matcher = TextMatcher()
        self.RTVTT_recognizer = RTVTT.RealTimeSpeechRecognizer()

        # è°ƒæ•´è¯†åˆ«å™¨å‚æ•°
        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source)

    def set_speech_manager(self, speech_manager: SpeechTextManager):
        """è®¾ç½®æ¼”è®²ç¨¿ç®¡ç†å™¨"""
        self.speech_manager = speech_manager

    def start_recognition(self):
        """å¼€å§‹è¯­éŸ³è¯†åˆ«"""
        if self.is_recognizing:
            return

        self.is_recognizing = True
        self.subtitles = []
        self.recognition_thread = threading.Thread(target=self._recognize_speech)
        self.recognition_thread.start()
        # print(

    def _recognize_speech(self):
        """è¯­éŸ³è¯†åˆ«çº¿ç¨‹"""
        start_time = time.time()

        while self.is_recognizing:
            try:
                with self.microphone as source:
                    # ç›‘å¬éŸ³é¢‘
                    audio = self.recognizer.listen(source, timeout=1, phrase_time_limit=5)

                try:
                    # è¯†åˆ«è¯­éŸ³ï¼ˆä½¿ç”¨Googleè¯­éŸ³è¯†åˆ«ï¼‰
                    # text = self.recognizer.recognize_google(audio, language='zh-CN')
                    # å®æ—¶è¯­éŸ³è¯†åˆ«ä½¿ç”¨é˜¿é‡Œäº‘
                    self.RTVTT_recognizer = RTVTT.get_RTVTT_recognizer()
                    # RTVTT.start_audio_stream(self.RTVTT_recognizer)
                    text = self.RTVTT_recognizer.last_complete_sentence

                    current_time = time.time() - start_time

                    # åˆ›å»ºå­—å¹•ç‰‡æ®µ
                    subtitle = SubtitleSegment(
                        start_time=current_time - 5,  # ä¼°ç®—å¼€å§‹æ—¶é—´
                        end_time=current_time,
                        text=text,
                        confidence=0.8  # é»˜è®¤ç½®ä¿¡åº¦
                    )

                    # å¦‚æœå¯ç”¨æ–‡ç¨¿ä¿®æ­£ï¼Œå°è¯•åŒ¹é…å¹¶ä¿®æ­£
                    if self.config.enable_script_correction and self.speech_manager:
                        self._correct_subtitle_with_script(subtitle)

                    self.subtitles.append(subtitle)
                    # print(

                except sr.UnknownValueError:
                    pass  # æ— æ³•è¯†åˆ«çš„éŸ³é¢‘

            except sr.WaitTimeoutError:
                pass  # è¶…æ—¶ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡ç›‘å¬
            except Exception as e:
                # print(
                time.sleep(1)

    def _correct_subtitle_with_script(self, subtitle: SubtitleSegment):
        """ä½¿ç”¨æ¼”è®²ç¨¿ä¿®æ­£å­—å¹•"""
        if not self.speech_manager:
            return

        # å°è¯•åŒ¹é…æ¼”è®²ç¨¿
        match_found, script_text, confidence = self.speech_manager.match_input_text(subtitle.text)

        if match_found and confidence > 0.3:  # å¦‚æœåŒ¹é…åº¦è¾ƒé«˜
            subtitle.corrected_text = script_text
            subtitle.is_corrected = True
            subtitle.confidence = confidence
            # print(

    def stop_recognition(self):
        """åœæ­¢è¯­éŸ³è¯†åˆ«"""
        if not self.is_recognizing:
            return

        self.is_recognizing = False
        if self.recognition_thread:
            self.recognition_thread.join()

        # print(

    def get_subtitles(self) -> List[SubtitleSegment]:
        """è·å–å­—å¹•åˆ—è¡¨"""
        return self.subtitles.copy()

    def export_subtitles(self, output_path: str, format_type: str = "srt"):
        """å¯¼å‡ºå­—å¹•æ–‡ä»¶"""
        if not self.subtitles:
            return

        if format_type.lower() == "srt":
            self._export_srt(output_path)
        elif format_type.lower() == "json":
            self._export_json(output_path)
        else:
            self._export_txt(output_path)

    def _export_srt(self, output_path: str):
        """å¯¼å‡ºSRTæ ¼å¼å­—å¹•"""
        with open(output_path, 'w', encoding='utf-8') as f:
            for i, subtitle in enumerate(self.subtitles, 1):
                start_time = self._format_srt_time(subtitle.start_time)
                end_time = self._format_srt_time(subtitle.end_time)
                text = subtitle.corrected_text if subtitle.is_corrected else subtitle.text

                f.write(f"{i}\n")
                f.write(f"{start_time} --> {end_time}\n")
                f.write(f"{text}\n\n")

    def _format_srt_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–SRTæ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

    def _export_json(self, output_path: str):
        """å¯¼å‡ºJSONæ ¼å¼å­—å¹•"""
        data = {
            "subtitles": [asdict(subtitle) for subtitle in self.subtitles],
            "export_time": datetime.now().isoformat()
        }
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def _export_txt(self, output_path: str):
        """å¯¼å‡ºçº¯æ–‡æœ¬æ ¼å¼å­—å¹•"""
        with open(output_path, 'w', encoding='utf-8') as f:
            for subtitle in self.subtitles:
                text = subtitle.corrected_text if subtitle.is_corrected else subtitle.text
                f.write(f"[{subtitle.start_time:.1f}s - {subtitle.end_time:.1f}s] {text}\n")

    def load_subtitles(self, file_path: str):
        """åŠ è½½å­—å¹•æ–‡ä»¶"""
        if file_path.endswith('.json'):
            self._load_json_subtitles(file_path)
        elif file_path.endswith('.srt'):
            self._load_srt_subtitles(file_path)
        else:
            self._load_txt_subtitles(file_path)

    def _load_json_subtitles(self, file_path: str):
        """åŠ è½½JSONæ ¼å¼å­—å¹•"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        self.subtitles = []
        for subtitle_data in data.get("subtitles", []):
            subtitle = SubtitleSegment(**subtitle_data)
            self.subtitles.append(subtitle)

    def _load_srt_subtitles(self, file_path: str):
        """åŠ è½½SRTæ ¼å¼å­—å¹•"""
        # ç®€åŒ–çš„SRTè§£æï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦æ›´å¼ºå¤§çš„è§£æå™¨
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„SRTè§£æé€»è¾‘
        print("SRTæ ¼å¼åŠ è½½åŠŸèƒ½éœ€è¦è¿›ä¸€æ­¥å®ç°")

    def _load_txt_subtitles(self, file_path: str):
        """åŠ è½½æ–‡æœ¬æ ¼å¼å­—å¹•"""
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        self.subtitles = []
        for i, line in enumerate(lines):
            line = line.strip()
            if line:
                # ç®€å•è§£æï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
                subtitle = SubtitleSegment(
                    start_time=i * 5,
                    end_time=(i + 1) * 5,
                    text=line
                )
                self.subtitles.append(subtitle)


class VideoRecordingAssistant:
    """å½•è§†é¢‘åŠ©æ‰‹ä¸»ç±»""" 
    
    def __init__(self):
        self.config = RecordingConfig()
        self.audio_recorder = None
        self.video_recorder = None
        self.speech_recognizer = None
        self.speech_manager = None

        self.is_recording = False
        self.output_dir = self.config.output_dir
        self.current_session_id = None

        # æ³¨æ„ï¼šä¸åœ¨åˆå§‹åŒ–æ—¶åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œè€Œæ˜¯åœ¨çœŸæ­£å¼€å§‹å½•åˆ¶æ—¶åˆ›å»º

    def set_speech_manager(self, speech_manager: SpeechTextManager):
        """è®¾ç½®æ¼”è®²ç¨¿ç®¡ç†å™¨"""
        self.speech_manager = speech_manager
        if self.speech_recognizer:
            self.speech_recognizer.set_speech_manager(speech_manager)

    def update_config(self, **kwargs):
        """æ›´æ–°å½•åˆ¶é…ç½®"""
        for key, value in kwargs.items():
            if hasattr(self.config, key):
                setattr(self.config, key, value)
        # print(

    def start_recording(self, floating_window=None):
        """å¼€å§‹å½•åˆ¶
        
        Args:
            floating_window: å¯é€‰çš„æ‚¬æµ®çª—å¯¹è±¡ï¼Œç”¨äºåœ¨å½•åˆ¶æ—¶æ’é™¤æ‚¬æµ®çª—åŒºåŸŸ
        """
        if self.is_recording:
            # print(
            return False

        # ç”Ÿæˆä¼šè¯ID
        self.current_session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        session_dir = os.path.join(self.output_dir, self.current_session_id)
        os.makedirs(session_dir, exist_ok=True)

        # print(

        try:
            # åˆå§‹åŒ–å½•åˆ¶å™¨
            if self.config.enable_microphone:
                self.audio_recorder = AudioRecorder(self.config)
                self.audio_recorder.start_recording()

            # åˆ›å»ºè§†é¢‘å½•åˆ¶å™¨æ—¶ä¼ é€’æ‚¬æµ®çª—å¯¹è±¡
            self.video_recorder = VideoRecorder(self.config, floating_window)
            video_path = os.path.join(session_dir, f"video_{self.current_session_id}.mp4")
            self.video_recorder.start_recording(video_path)

            if self.config.enable_ai_subtitles:
                self.speech_recognizer = SpeechRecognizer(self.config)
                if self.speech_manager:
                    self.speech_recognizer.set_speech_manager(self.speech_manager)
                self.speech_recognizer.start_recognition()

            self.is_recording = True
            # print(
            return True

        except Exception as e:
            # print(
            self.stop_recording()
            return False

    def stop_recording(self):
        """åœæ­¢å½•åˆ¶"""
        if not self.is_recording:
            return

        # print(

        try:
            # åœæ­¢éŸ³é¢‘å½•åˆ¶
            if self.audio_recorder:
                session_dir = os.path.join(self.output_dir, self.current_session_id)
                audio_path = os.path.join(session_dir, f"audio_{self.current_session_id}.wav")
                self.audio_recorder.stop_recording(audio_path)
                self.audio_recorder.cleanup()

            # åœæ­¢è§†é¢‘å½•åˆ¶
            if self.video_recorder:
                self.video_recorder.stop_recording()

            # åœæ­¢è¯­éŸ³è¯†åˆ«
            if self.speech_recognizer:
                self.speech_recognizer.stop_recognition()

                # å¯¼å‡ºå­—å¹•
                session_dir = os.path.join(self.output_dir, self.current_session_id)
                subtitle_path = os.path.join(session_dir, f"subtitles_{self.current_session_id}.json")
                self.speech_recognizer.export_subtitles(subtitle_path, "json")

                # ä¹Ÿå¯¼å‡ºSRTæ ¼å¼
                srt_path = os.path.join(session_dir, f"subtitles_{self.current_session_id}.srt")
                self.speech_recognizer.export_subtitles(srt_path, "srt")

            self.is_recording = False
            # print(

            # å°è¯•åˆå¹¶éŸ³è§†é¢‘
            self._merge_audio_video()

        except Exception as e:
            print(f"åœæ­¢å½•åˆ¶æ—¶å‡ºé”™: {e}")

    def _merge_audio_video(self):
        """åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶"""
        if not self.current_session_id:
            return

        try:
            session_dir = os.path.join(self.output_dir, self.current_session_id)
            video_path = os.path.join(session_dir, f"video_{self.current_session_id}.mp4")
            audio_path = os.path.join(session_dir, f"audio_{self.current_session_id}.wav")
            output_path = os.path.join(session_dir, f"final_{self.current_session_id}.mp4")

            if os.path.exists(video_path) and os.path.exists(audio_path):
                # ä½¿ç”¨ffmpegåˆå¹¶éŸ³è§†é¢‘
                input_video = ffmpeg.input(video_path)
                input_audio = ffmpeg.input(audio_path)

                out = ffmpeg.output(
                    input_video, input_audio,
                    output_path,
                    vcodec='copy',
                    acodec='aac'
                )
                ffmpeg.run(out, overwrite_output=True, quiet=True)

                # print(

        except Exception as e:
            print(f"åˆå¹¶éŸ³è§†é¢‘æ—¶å‡ºé”™: {e}")

    def get_recording_status(self) -> Dict:
        """è·å–å½•åˆ¶çŠ¶æ€"""
        status = {
            "is_recording": self.is_recording,
            "session_id": self.current_session_id,
            "duration": 0,
            "config": asdict(self.config)
        }

        if self.video_recorder and self.is_recording:
            status["duration"] = self.video_recorder.get_recording_duration()

        return status

    def get_current_subtitles(self) -> List[SubtitleSegment]:
        """è·å–å½“å‰å­—å¹•"""
        if self.speech_recognizer:
            return self.speech_recognizer.get_subtitles()
        return []

    def edit_subtitle(self, index: int, new_text: str):
        """ç¼–è¾‘å­—å¹•"""
        if self.speech_recognizer and 0 <= index < len(self.speech_recognizer.subtitles):
            self.speech_recognizer.subtitles[index].text = new_text
            self.speech_recognizer.subtitles[index].is_corrected = True
            # print(

    def export_subtitles(self, output_path: str, format_type: str = "srt"):
        """å¯¼å‡ºå­—å¹•"""
        if self.speech_recognizer:
            self.speech_recognizer.export_subtitles(output_path, format_type)

    def load_subtitles(self, file_path: str):
        """åŠ è½½å­—å¹•æ–‡ä»¶"""
        if not self.speech_recognizer:
            self.speech_recognizer = SpeechRecognizer(self.config)
        self.speech_recognizer.load_subtitles(file_path)


def test_video_recording_assistant():
    """æµ‹è¯•å½•è§†é¢‘åŠ©æ‰‹"""
    print("=== å½•è§†é¢‘åŠ©æ‰‹æµ‹è¯• ===")

    # åˆ›å»ºåŠ©æ‰‹å®ä¾‹
    assistant = VideoRecordingAssistant()

    # é…ç½®å½•åˆ¶å‚æ•°
    assistant.update_config(
        enable_screen=True,
        enable_camera=False,  # æµ‹è¯•æ—¶å…³é—­æ‘„åƒå¤´
        enable_microphone=True,
        enable_ai_subtitles=True,
        enable_script_correction=False
    )

    print("é…ç½®å®Œæˆï¼ŒæŒ‰Enterå¼€å§‹å½•åˆ¶...")
    input()

    # å¼€å§‹å½•åˆ¶
    if assistant.start_recording():
        print("å½•åˆ¶ä¸­... æŒ‰Enteråœæ­¢å½•åˆ¶")
        input()

        # åœæ­¢å½•åˆ¶
        assistant.stop_recording()

        # æ˜¾ç¤ºçŠ¶æ€
        status = assistant.get_recording_status()
        print(f"å½•åˆ¶çŠ¶æ€: {status}")

        # æ˜¾ç¤ºå­—å¹•
        subtitles = assistant.get_current_subtitles()
        print(f"ç”Ÿæˆäº† {len(subtitles)} æ¡å­—å¹•")
        for i, subtitle in enumerate(subtitles):
            print(f"{i + 1}. [{subtitle.start_time:.1f}s-{subtitle.end_time:.1f}s] {subtitle.text}")


if __name__ == "__main__":
    test_video_recording_assistant()
